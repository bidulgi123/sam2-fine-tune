{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm           \n",
    "import copy\n",
    "import random \n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1, 2, 3, 4\"\n",
    "\n",
    "available_fonts = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "if any('Arial' in font for font in available_fonts):\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "else:\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "device = 'cuda:1'\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders = True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "#Random positive points\n",
    "def positive_random_point(binary_image, n, random_num=False):\n",
    "    dilate_binary_image = cv2.erode(binary_image, None, iterations=1)\n",
    "    points = np.argwhere(dilate_binary_image > 0)\n",
    "    points = points[:, ::-1] \n",
    "    if random_num :\n",
    "        chosen_indices = np.random.choice(len(points), np.random.randint(1, n + 1), replace=False)\n",
    "    else :\n",
    "        chosen_indices = np.random.choice(len(points), n, replace=False)\n",
    "    random_points = points[chosen_indices]\n",
    "    return random_points  # (n, 2) \n",
    "\n",
    "#Random nagative foint\n",
    "def negative_random_point(binary_image, n, random_num=False):\n",
    "    before_points = cv2.dilate(binary_image, None, iterations=30)\n",
    "    dilate_binary_image = cv2.dilate(binary_image, None, iterations=15)\n",
    "    after_points = before_points - dilate_binary_image \n",
    "    points = np.argwhere(after_points > 0)\n",
    "    points = points[:, ::-1]  \n",
    "    if random_num :\n",
    "        chosen_indices = np.random.choice(len(points), np.random.randint(1, n + 1), replace=False)\n",
    "    else :\n",
    "        chosen_indices = np.random.choice(len(points), n, replace=False)\n",
    "    random_points = points[chosen_indices]\n",
    "    return random_points  \n",
    "\n",
    "def show_masks_together(image, masks, masks_overlay, scores, point_coords=None, box_coords=None, input_labels=None, borders=True, save_path=None):\n",
    "   \n",
    "    # 2x2 subplot \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))  \n",
    "\n",
    "    #Original Image\n",
    "    axs[0, 0].imshow(image)\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(\"Original Image\", fontsize=16)\n",
    "\n",
    "    #Mask overlay\n",
    "    axs[0, 1].imshow(masks_overlay)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title(\"Masks Overlay\", fontsize=16)\n",
    "\n",
    "    #Image and points\n",
    "    axs[1, 0].imshow(image)\n",
    "    if point_coords is not None:\n",
    "        assert input_labels is not None\n",
    "        show_points(point_coords, input_labels, axs[1, 0])\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title(\"Initial Points Visualization\", fontsize=16)\n",
    "\n",
    "    #Show mask\n",
    "    axs[1, 1].imshow(image)\n",
    "    for i, mask in enumerate(masks):\n",
    "        show_mask(mask, axs[1, 1], borders=borders)\n",
    "        if point_coords is not None:\n",
    "            show_points(point_coords, input_labels, axs[1, 1])\n",
    "        if box_coords is not None:\n",
    "            show_box(box_coords, axs[1, 1])\n",
    "    axs[1, 1].set_title(f\"Mask {i+1}, Score: {scores:.3f}\", fontsize=16)\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def calculate_dice_score(pred_mask, gt_mask):\n",
    "\n",
    "    pred_mask_binary = (pred_mask > 0.5).astype(np.uint8)  \n",
    "    gt_mask_binary = (gt_mask > 0.5).astype(np.uint8)      \n",
    "    dice_score = f1_score(gt_mask_binary.flatten(), pred_mask_binary.flatten())\n",
    "\n",
    "    return dice_score\n",
    "\n",
    "def visualize_images(images, titles, cmap='gray', figsize=(10, 5)):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=figsize)  \n",
    "    for i, (image, title) in enumerate(zip(images, titles)):\n",
    "        axes[i].imshow(image.detach().cpu().numpy(), cmap=cmap)  \n",
    "        axes[i].axis('off')  \n",
    "        axes[i].set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "prd_titles = [f\"Pred {i+1}\" for i in range(4)]  \n",
    "visualize_images(prd_masks[:4], prd_titles)\n",
    "\n",
    "gt_titles = [f\"Ground Truth {i+1}\" for i in range(4)]  \n",
    "visualize_images(gt_mask[:4], gt_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    #Brightness and Contrast Control\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.6),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, masks_paths, masks_overlay_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.masks_paths = masks_paths\n",
    "        self.masks_overlay_paths = masks_overlay_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]))\n",
    "        mask = np.array(Image.open(self.masks_paths[idx]))\n",
    "        mask_overlay = np.array(Image.open(self.masks_overlay_paths[idx]))  \n",
    "        file_name = os.path.basename(self.masks_overlay_paths[idx])\n",
    "     \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            #(c, w ,h) -> (w, h, c)\n",
    "            image = augmented['image'].permute(1, 2, 0)\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        return image, mask, mask_overlay, file_name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "data_dir = 'path'\n",
    "image_dir = os.path.join(data_dir, 'Input', 'png')                       \n",
    "mask_dir = os.path.join(data_dir, 'Mask', 'extracted')\n",
    "mask_overlay_dir = os.path.join(data_dir, 'Mask', 'raw')\n",
    "image_path = np.sort(glob.glob(os.path.join(image_dir,'*.png')))\n",
    "mask_path = np.sort(glob.glob(os.path.join(data_dir, 'Mask', 'extracted','*.png')))\n",
    "mask_overlay_path = np.sort(glob.glob(os.path.join(data_dir, 'Mask', 'raw','*.png')))\n",
    "# print(len(image_path), len(mask_path))\n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation, test dataset split\n",
    "_batch_size = 4\n",
    "\n",
    "train_split = 0.7\n",
    "valid_split = 0.1\n",
    "test_split = 0.2\n",
    "\n",
    "train_image_path = image_path[:int(len(image_path) * train_split)]\n",
    "train_mask_path = mask_path[:int(len(mask_path) * train_split)]\n",
    "\n",
    "valid_image_path = image_path[int(len(image_path) * train_split):int(len(image_path) * (train_split + valid_split))]\n",
    "valid_mask_path = mask_path[int(len(mask_path) * train_split):int(len(mask_path) * (train_split + valid_split))]\n",
    "\n",
    "test_image_path = image_path[int(len(image_path) * (train_split + valid_split)):]\n",
    "test_mask_path = mask_path[int(len(mask_path) * (train_split + valid_split)):]\n",
    "test_mask_overlay_path = mask_path[int(len(mask_path) * (train_split + valid_split)):]\n",
    "\n",
    "train_dataset = CustomDataset(train_image_path, train_mask_path, mask_overlay_path, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=_batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = CustomDataset(valid_image_path, valid_mask_path, mask_overlay_path, transform=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=_batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = CustomDataset(test_image_path, test_mask_path, test_mask_overlay_path, transform=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "sam2_checkpoint = \"../checkpoints/sam2.1_hiera_base_plus.pt\"\n",
    "model_cfg = \"../sam2/configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "sam2_model.sam_mask_decoder.train(True)\n",
    "sam2_model.sam_prompt_encoder.train(True)\n",
    "sam2_model.image_encoder.train(False)\n",
    "print('predictor.model.sam_mask_decoder.training :', predictor.model.sam_mask_decoder.training)  \n",
    "print('predictor.model.sam_prompt_encoder.training :', predictor.model.sam_prompt_encoder.training)  \n",
    "print('predictor.model.image_encoder.training :', predictor.model.image_encoder.training)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = torch.optim.AdamW(params=predictor.model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "num_epochs = 50\n",
    "epsilon = 1e-6\n",
    "train_loss_history = []\n",
    "train_dice_history = []\n",
    "val_f1_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_dice = 0\n",
    "    non_data = 0\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    with tqdm(train_dataloader, desc=f\"🚀 Epoch {epoch+1}/{num_epochs} - Training\", unit=\"batch\", colour=\"green\", dynamic_ncols=True) as tbar:\n",
    "        for images, masks, _, _ in tbar:\n",
    "            \n",
    "            batch_size = images.shape[0]\n",
    "            batch_image = []\n",
    "            batch_mask = []\n",
    "            batch_point = []\n",
    "            batch_label = []\n",
    "            \n",
    "            # Skip processing if the current batch size is smaller than the defined batch size    \n",
    "            if images.shape[0] < _batch_size : \n",
    "                non_data = images.shape[0]\n",
    "                break\n",
    "                \n",
    "            for i in range(batch_size):\n",
    "                \n",
    "                image = images[i].cpu().numpy()\n",
    "                mask = masks[i].cpu().numpy()\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "                _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "                # Generate random positive and negative points for the mask\n",
    "                positive_point = positive_random_point(mask, 1)\n",
    "                negative_point = negative_random_point(mask, 1)\n",
    "                negative_input_label = np.zeros((len(negative_point),), dtype=np.uint8)\n",
    "                input_label = np.ones((len(positive_point),), dtype=np.uint8) \n",
    "                _input_point = np.concatenate((positive_point, negative_point), axis=0)\n",
    "                _input_label = np.concatenate((input_label, negative_input_label), axis=0)\n",
    "        \n",
    "                batch_image.append(image)\n",
    "                batch_mask.append(mask)\n",
    "                batch_point.append(_input_point)\n",
    "                batch_label.append(_input_label)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                predictor.set_image_batch(batch_image)\n",
    "                \n",
    "                # predictor._prep_prompts\n",
    "                # 예측 과정에서 사용할 포인트와 라벨을 준비.\n",
    "                # normalize_coords: 좌표를 정규화하여 모델 입력 크기에 맞게 조정.\n",
    "                _, point_ccoordinate, labels, _ = predictor._prep_prompts(\n",
    "                np.array(batch_point), np.array(batch_label), box=None, mask_logits=None, normalize_coords=True\n",
    "                )\n",
    "                \n",
    "                # sparse_embeddings, dense_embeddings\n",
    "                # SAM2의 Prompt Encoder를 사용하여 포인트와 라벨을 기반으로 sparse와 dense 프롬프트 임베딩을 생성.\n",
    "                # sparse_embeddings: 포인트 기반으로 생성된 sparse 임베딩.\n",
    "                # dense_embeddings: 전체 이미지의 dense 임베딩(포인트의 주변 영역 포함).\n",
    "                sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
    "                points=(point_ccoordinate, labels), boxes=None, masks=None,\n",
    "                )\n",
    "                \n",
    "                # high_res_features\n",
    "                # SAM2의 예측에 필요한 고해상도 특징맵을 생성.\n",
    "                # high_res_features는 predictor._features에서 \"high_res_feats\"라는 키를 사용하여 추출된 고해상도 피처맵을 가져옴\n",
    "                high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
    "                \n",
    "                # low_res_masks, prd_scores\n",
    "                # SAM2의 Mask Decoder를 호출하여 저해상도 마스크(low_res_masks)와 점수(prd_scores)를 예측합니다.\n",
    "                # image_embeddings: image encoding info.\n",
    "                # image_pe: image positional encoding info.\n",
    "                # sparse_prompt_embeddings: sparse embeddings.\n",
    "                # dense_prompt_embeddings: dense embeddings.\n",
    "                # high_res_features: 고해상도 피처맵 정보.\n",
    "                low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
    "                image_embeddings=predictor._features[\"image_embed\"],\n",
    "                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparse_embeddings,\n",
    "                dense_prompt_embeddings=dense_embeddings,\n",
    "                multimask_output=False,\n",
    "                repeat_image=False,\n",
    "                high_res_features=high_res_features,\n",
    "                )\n",
    "                    \n",
    "                #Post-process predicted masks\n",
    "                prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
    "                \n",
    "                #[batch, channel, w, h] - > [batch, channel, w, h]\n",
    "                prd_masks = prd_masks[:, 0].squeeze(0)\n",
    "                \n",
    "                #to use sigmoid logit \n",
    "                prd_masks = torch.sigmoid(prd_masks)\n",
    "                prd_masks = prd_masks.squeeze(1)\n",
    "\n",
    "                #Ground truth masks\n",
    "                gt_mask = torch.tensor((np.array(batch_mask) / 255).astype(np.float32), device=device)\n",
    "                \n",
    "                #To use dice loss function\n",
    "                intersection = torch.sum(gt_mask * prd_masks, dim=(1, 2))  \n",
    "                total = torch.sum(gt_mask, dim=(1, 2)) + torch.sum(prd_masks, dim=(1, 2))  \n",
    "                dice = (2. * intersection + epsilon) / (total + epsilon)\n",
    "                loss = 1 - dice \n",
    "                loss = loss.mean()\n",
    "                epoch_loss += loss.item() \n",
    "                epoch_dice += dice.mean().item()\n",
    "\n",
    "            #Backpropagation\n",
    "            predictor.model.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "    #Time check\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    \n",
    "    epoch_loss = epoch_loss/(len(train_dataloader) - non_data)\n",
    "    epoch_dice = epoch_dice/(len(train_dataloader) - non_data)\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    train_dice_history.append(epoch_dice)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Dice: {epoch_dice:.4f}\")\n",
    "    print(f\"Epoch {epoch+1} Processing time: {epoch_duration:.2f} seconds.\")\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == num_epochs - 1  :\n",
    "        #evaluate mode -> Train = False\n",
    "        sam2_model.eval()\n",
    "        \n",
    "        val_dice_list = []\n",
    "        \n",
    "        with tqdm(valid_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", unit=\"batch\") as vbar:\n",
    "            for images, masks, mask_overlays, file_names in vbar:\n",
    "                batch_size = images.shape[0]  \n",
    "                with torch.no_grad():\n",
    "                    for i in range(batch_size):\n",
    "                        with torch.no_grad():\n",
    "                            image = images[i].cpu().numpy()\n",
    "                            mask = masks[i].cpu().numpy()\n",
    "                            mask_overlay = mask_overlays[i]\n",
    "                            file_name = file_names[i]\n",
    "                            mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "                            _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "                            \n",
    "                            positive_point = positive_random_point(mask, 2)\n",
    "                            positive_point_label = np.ones((len(positive_point),), dtype=np.uint8)\n",
    "\n",
    "                            # Generate random negative points (use if needed)\n",
    "                            # negative_point = negative_random_point(mask, 1)\n",
    "                            # negative_point_label = np.zeros((len(negative_point),), dtype=np.uint8)\n",
    "                            \n",
    "                            # _input_point = np.concatenate((positive_point, negative_point), axis=0)\n",
    "                            # _input_label = np.concatenate((positive_point_label, negative_point_label), axis=0)\n",
    "                            \n",
    "                            with torch.cuda.amp.autocast():\n",
    "                                predictor.set_image(image)\n",
    "                                predict_masks, predict_scores, predict_logits = predictor.predict(\n",
    "                                point_coords=positive_point,\n",
    "                                point_labels=positive_point_label,\n",
    "                                multimask_output=False)\n",
    "                                \n",
    "                    val_dice_score = calculate_dice_score(mask, predict_masks[0])\n",
    "                    val_dice_list.append(val_dice_score)\n",
    "                    \n",
    "        val_f1_history.append(np.mean(val_dice_list))\n",
    "        \n",
    "        print(f\"Validation F1 Score: {np.mean(val_dice_list):.4f}, Median : {np.median(val_dice_list):.4f}\")\n",
    "                        \n",
    "        # Set the model components to training mode before switching to evaluation mode\n",
    "        sam2_model.sam_mask_decoder.train(True)\n",
    "        sam2_model.sam_prompt_encoder.train(True)\n",
    "        sam2_model.image_encoder.train(False)\n",
    "       \n",
    "#🚀 Epoch 1/50 - Training: 100%|██████████████████████████████████████████████████████████████████████▉| 1242/1243 [08:28<00:00,  2.44batch/s]\n",
    "#Epoch 1, Loss: 0.2385, Dice: 0.7631\n",
    "#Epoch 1 Processing time: 508.72 seconds.\n",
    "#🚀 Epoch 2/50 - Training: 100%|██████████████████████████████████████████████████████████████████████▉| 1242/1243 [06:24<00:00,  3.23batch/s]\n",
    "#Epoch 2, Loss: 0.1881, Dice: 0.8135\n",
    "#Epoch 2 Processing time: 384.01 seconds.\n",
    "#🚀 Epoch 3/50 - Training: 100%|██████████████████████████████████████████████████████████████████████▉| 1242/1243 [06:23<00:00,  3.24batch/s]\n",
    "#Epoch 3, Loss: 0.1735, Dice: 0.8281\n",
    "#Epoch 3 Processing time: 383.79 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model_type = 'float16' if sam2_model.parameters().__next__().dtype == torch.float16 else 'float32'\n",
    "torch.save({'model_state_dict': sam2_model.state_dict(), 'model_type': model_type}, 'sam2_model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss_history, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Dice \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_dice_history, label='Training Dice', color='green')\n",
    "plt.plot(val_f1_history, label='Validation F1 Score', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice / F1 Score')\n",
    "plt.title('Training Dice and Validation F1 Score Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "checkpoint = torch.load('sam2_model.torch')\n",
    "new_sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "new_sam2_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "new_predictor = SAM2ImagePredictor(new_sam2_model)\n",
    "new_predictor.model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To organize results in a directory named with the current timestamp\n",
    "korea_timezone = pytz.timezone('Asia/Seoul')\n",
    "korea_time = datetime.now(korea_timezone).strftime(\"%Y-%m-%d-%H:%M:%S \")\n",
    "save_dir = f'results-local/positive_random/{korea_time} N'\n",
    "if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "test_file_name = []\n",
    "test_dice_scores = [] \n",
    "\n",
    "# Use tqdm with a dynamic update of the Dice score\n",
    "with tqdm(test_dataloader, desc=\"🚀 Testing \", unit=\"batch\", colour=\"blue\") as tbar:\n",
    "    for images, masks, mask_overlays, file_names in tbar:\n",
    "        batch_loss = 0.0\n",
    "        batch_dice = 0.0  \n",
    "        batch_size = images.shape[0]  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(batch_size):\n",
    "                image = images[i].cpu().numpy()\n",
    "                mask = masks[i].cpu().numpy()\n",
    "                mask_overlay = mask_overlays[i]\n",
    "                file_name = file_names[i]\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "                _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                # Generate random positive points\n",
    "                positive_point = positive_random_point(mask, 2)\n",
    "                positive_point_label = np.ones((len(positive_point),), dtype=np.uint8)\n",
    "\n",
    "                # Generate random negative points (use if needed)\n",
    "                # negative_point = negative_random_point(mask, 1)\n",
    "                # negative_point_label = np.zeros((len(negative_point),), dtype=np.uint8)\n",
    "                \n",
    "                # _input_point = np.concatenate((positive_point, negative_point), axis=0)\n",
    "                # _input_label = np.concatenate((positive_point_label, negative_point_label), axis=0)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    new_predictor.set_image(image)\n",
    "                    predict_masks, predict_scores, predict_logits = new_predictor.predict(\n",
    "                        point_coords=positive_point,\n",
    "                        point_labels=positive_point_label,\n",
    "                        multimask_output=False)\n",
    "                \n",
    "                test_dice = calculate_dice_score(mask, predict_masks[0])\n",
    "                show_masks_together(image, predict_masks, mask_overlay, test_dice, point_coords=positive_point, input_labels=positive_point_label, borders=True, save_path=f'{save_dir}/{file_name}')\n",
    "                \n",
    "                test_dice_scores.append(test_dice)\n",
    "                test_file_name.append(file_name)\n",
    "\n",
    "            # Calculate the mean Dice score for the batch\n",
    "            mean_dice = np.mean(test_dice_scores)\n",
    "            tbar.set_postfix(mean_dice=mean_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['file_name'] = [f_name for f_name in test_file_name]\n",
    "df['fine_tune'] = [d_score for d_score in test_dice_scores]\n",
    "\n",
    "plt.figure(figsize=(5,7))\n",
    "sns.boxplot(df['fine_tune'],showmeans=True,\n",
    "            meanprops={'marker':'o',\n",
    "                       'markerfacecolor':'white', \n",
    "                       'markeredgecolor':'black',\n",
    "                       'markersize':'5'})\n",
    "\n",
    "plt.title(f\"f1-score comparison (mean: {np.mean(df['fine_tune']):.2f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
