{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm           \n",
    "import copy\n",
    "import random \n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1, 2, 3, 4\"\n",
    "\n",
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # use bfloat16 for the entire notebook\n",
    "    torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "elif device.type == \"mps\":\n",
    "    print(\n",
    "        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n",
    "        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n",
    "        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n",
    "    )\n",
    "    \n",
    "plt.rcParams['font.family'] = 'Arial' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders = True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))    \n",
    "\n",
    "def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show\n",
    "        \n",
    "def extract_random_points(binary_image, n):\n",
    "    dilate_binary_image = cv2.erode(binary_image, None, iterations=1)\n",
    "    points = np.argwhere(dilate_binary_image > 0)\n",
    "    points = points[:, ::-1] \n",
    "    chosen_indices = np.random.choice(len(points), np.random.randint(1, n + 1), replace=False)\n",
    "    random_points = points[chosen_indices]\n",
    "    return random_points  # (n, 2) \n",
    "    \n",
    "def negative_random_point(binary_image, n):\n",
    "    before_points = cv2.dilate(binary_image, None, iterations=40)\n",
    "    dilate_binary_image = cv2.dilate(binary_image, None, iterations=25)\n",
    "    after_points = before_points - dilate_binary_image \n",
    "    points = np.argwhere(after_points > 0)\n",
    "    points = points[:, ::-1]  \n",
    "    chosen_indices = np.random.choice(len(points), np.random.randint(1, n + 1), replace=False)\n",
    "    random_points = points[chosen_indices]\n",
    "    return random_points     \n",
    "    \n",
    "def show_masks_together(image, masks, masks_overlay, scores, point_coords=None, box_coords=None, input_labels=None, borders=True, save_path=None):\n",
    "   \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))  \n",
    "    axs[0, 0].imshow(image)\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 0].set_title(\"Original Image\", fontsize=16)\n",
    "\n",
    "    axs[0, 1].imshow(masks_overlay)\n",
    "    axs[0, 1].axis('off')\n",
    "    axs[0, 1].set_title(\"Masks Overlay\", fontsize=16)\n",
    "\n",
    "    axs[1, 0].imshow(image)\n",
    "    if point_coords is not None:\n",
    "        assert input_labels is not None\n",
    "        show_points(point_coords, input_labels, axs[1, 0])\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[1, 0].set_title(\"Initial Points Visualization\", fontsize=16)\n",
    "\n",
    "    axs[1, 1].imshow(image)\n",
    "    for i, mask in enumerate(masks):\n",
    "        show_mask(mask, axs[1, 1], borders=borders)\n",
    "        if point_coords is not None:\n",
    "            show_points(point_coords, input_labels, axs[1, 1])\n",
    "        if box_coords is not None:\n",
    "            show_box(box_coords, axs[1, 1])\n",
    "    axs[1, 1].set_title(f\"Mask {i+1}, Score: {scores:.3f}\", fontsize=16)\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def calculate_f1_score(true_mask, pred_mask):\n",
    "\n",
    "    true_mask = true_mask.flatten()\n",
    "    pred_mask = pred_mask.flatten()\n",
    "\n",
    "    tp = np.sum((true_mask == 1) & (pred_mask == 1))\n",
    "    fp = np.sum((true_mask == 0) & (pred_mask == 1))\n",
    "    fn = np.sum((true_mask == 1) & (pred_mask == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, masks_paths, masks_overlay_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.masks_paths = masks_paths\n",
    "        self.masks_overlay_paths = masks_overlay_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]))\n",
    "        mask = np.array(Image.open(self.masks_paths[idx]))\n",
    "        mask_overlay = np.array(Image.open(self.masks_overlay_paths[idx]))  \n",
    "        file_name = os.path.basename(self.masks_overlay_paths[idx])\n",
    "     \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            #(c, w ,h) -> (w, h, c)\n",
    "            image = augmented['image'].permute(1, 2, 0)\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        return image, mask, mask_overlay, file_name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "data_dir = 'path'\n",
    "image_dir = os.path.join(data_dir, 'Input', 'png')                       \n",
    "mask_dir = os.path.join(data_dir, 'Mask', 'extracted')\n",
    "mask_overlay_dir = os.path.join(data_dir, 'Mask', 'raw')\n",
    "image_path = np.sort(glob.glob(os.path.join(image_dir,'*.png')))\n",
    "mask_path = np.sort(glob.glob(os.path.join(data_dir, 'Mask', 'extracted','*.png')))\n",
    "mask_overlay_path = np.sort(glob.glob(os.path.join(data_dir, 'Mask', 'raw','*.png')))\n",
    "# print(len(image_path), len(mask_path))\n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=1),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "_batch_size = 8\n",
    "train_image_path = image_path[:int(len(image_path) * 0.8)]\n",
    "train_mask_path = mask_path[:int(len(mask_path) * 0.8)]\n",
    "dataset = CustomDataset(train_image_path, train_mask_path, mask_overlay_path, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=_batch_size, shuffle=True)\n",
    "\n",
    "#model\n",
    "sam2_checkpoint = \"../checkpoints/sam2.1_hiera_small.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "predictor = SAM2ImagePredictor(sam2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#Mixed Precision Training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=predictor.model.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.2)\n",
    "\n",
    "#gradient accumulation\n",
    "accumulation_steps = 4\n",
    "\n",
    "#predictor train mode \n",
    "predictor.model.sam_mask_decoder.train(True)\n",
    "predictor.model.sam_prompt_encoder.train(True)\n",
    "predictor.model.image_encoder.train(False)\n",
    "\n",
    "num_epochs = 2\n",
    "epsilon = 1e-6\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "        \n",
    "    for images, masks, _, _ in tqdm(dataloader):\n",
    "        batch_size = images.shape[0]\n",
    "        batch_loss = 0.0\n",
    "        batch_dice = 0.0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            with torch.cuda.amp.autocast():\n",
    "\n",
    "                image = images[i].cpu().numpy()\n",
    "                mask = masks[i].cpu().numpy()\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "                _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "                # 랜덤 포인트 생성\n",
    "                positive_point = extract_random_points(mask, 5)\n",
    "                negative_point = negative_random_point(mask, 5)\n",
    "                negative_input_label = np.zeros((len(negative_point),), dtype=np.uint8)\n",
    "                input_label = np.ones((len(positive_point),), dtype=np.uint8) \n",
    "                _input_point = np.concatenate((positive_point, negative_point), axis=0)\n",
    "                _input_label = np.concatenate((input_label, negative_input_label), axis=0)\n",
    "\n",
    "                ## \n",
    "                # Parts to be modified -> set_image_batch\n",
    "                ##\n",
    "                predictor.set_image(image) \n",
    "                \n",
    "                mask_input, point_ccoordinate, labels, _ = predictor._prep_prompts(\n",
    "                    _input_point, _input_label, box=None, mask_logits=None, normalize_coords=True\n",
    "                )\n",
    "            \n",
    "                # 프롬프트 인코더를 사용해 희소(sparse) 및 밀집(dense) 임베딩을 생성\n",
    "                sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
    "                    points=(point_ccoordinate, labels), boxes=None, masks=None,\n",
    "                )\n",
    "            \n",
    "                # predictor의 고해상도(high resolution) 특징 맵을 추출하고, 이를 리스트로 저장\n",
    "                # 각 특성 맵에서 마지막 레벨을 선택하여 고해상도 특징을 표현. `unsqueeze(0)`은 배치 차원을 추가\n",
    "                high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
    "            \n",
    "                # SAM 마스크 디코더를 호출하여 마스크 예측(low_res_masks)과 점수(prd_scores)를 생성\n",
    "                low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
    "                    image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),  # 마지막 이미지 임베딩에서 배치 차원을 추가하여 전달\n",
    "                    image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),            # 밀집 위치 인코딩을 가져와서 전달\n",
    "                    sparse_prompt_embeddings=sparse_embeddings,                             \n",
    "                    dense_prompt_embeddings=dense_embeddings,                               \n",
    "                    multimask_output=False,                                                 # 단일 마스크 예측 모드로 설정                \n",
    "                    repeat_image = 1,\n",
    "                    high_res_features=high_res_features,                                    # 고해상도 특징 맵을 디코더에 전달\n",
    "                )\n",
    "    \n",
    "                # Dice 계산\n",
    "                gt_mask = torch.tensor((mask / 255).astype(np.float32), device='cuda', requires_grad=False)\n",
    "                prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
    "                prd_mask = prd_masks[:, 0]\n",
    "                prd_mask = prd_mask.squeeze(0)\n",
    "                prd_mask = torch.sigmoid(prd_mask)\n",
    "                \n",
    "                inter = torch.sum(prd_mask * gt_mask)\n",
    "                gt_sum = torch.sum(gt_mask)\n",
    "                prd_sum = torch.sum(prd_mask)\n",
    "                dice_coef = (2 * inter) / (gt_sum + prd_sum + epsilon)\n",
    "                dice_loss = 1 - dice_coef\n",
    "    \n",
    "                #ce loss\n",
    "                seg_loss = - (gt_mask * torch.log(prd_mask + epsilon) + (1 - gt_mask) * torch.log(1 - prd_mask + epsilon)).mean()\n",
    "    \n",
    "                #If the last batch is not divisible by accumulation_steps\n",
    "                if i >= batch_size - batch_size % accumulation_steps:\n",
    "                    accumulation_steps = batch_size % accumulation_steps or accumulation_steps\n",
    "                    \n",
    "                # f1 = calculate_f1_score_tensor(prd_mask, gt_mask)\n",
    "                # loss = dice_loss + seg_loss\n",
    "                loss = dice_loss\n",
    "                \n",
    "                batch_loss += loss.item()\n",
    "                batch_dice += dice_coef.item()\n",
    "                \n",
    "                loss = loss / accumulation_steps\n",
    "                \n",
    "            # Exits ``autocast`` before backward(). \n",
    "            # Backward passes under ``autocast`` are not recommended. \n",
    "            # Backward ops run in the same ``dtype`` ``autocast`` chose for corresponding forward ops.\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # 일정한 Step마다 가중치 업데이트\n",
    "            if (i + 1) % accumulation_steps == 0 or i == batch_size - 1:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        #Batch Loss and Dice Average\n",
    "        batch_loss /= batch_size\n",
    "        batch_dice /= batch_size\n",
    "        running_loss += batch_loss\n",
    "        running_dice += batch_dice\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader):.4f}, Dice: {running_dice/len(dataloader):.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 711/711 [12:32<00:00,  1.06s/it]\n",
    "# Epoch 1, Loss: 0.3829, Dice: 0.6171\n",
    "# 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 711/711 [12:27<00:00,  1.05s/it]\n",
    "# Epoch 2, Loss: 0.2937, Dice: 0.7063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = image_path[int(len(image_path) * 0.8):]\n",
    "test_mask_path = mask_path[int(len(mask_path) * 0.8):]\n",
    "test_mask_overlay_path = mask_path[int(len(mask_path) * 0.8):]\n",
    "test_dataset = CustomDataset(test_image_path, test_mask_path, test_mask_overlay_path, transform=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Parts to be modified\n",
    "##\n",
    "torch.save(predictor.model.state_dict(), f'test_model_parameters.torch')\n",
    "new_sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "new_predictor = SAM2ImagePredictor(new_sam2_model)\n",
    "new_predictor.model.load_state_dict(torch.load('test_model_parameters.torch'))\n",
    "predictor.model.eval()\n",
    "new_predictor.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korea_timezone = pytz.timezone('Asia/Seoul')\n",
    "korea_time = datetime.now(korea_timezone).strftime(\"%Y-%m-%d-%H:%M:%S \")\n",
    "save_dir = f'path/{korea_time} N'\n",
    "if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "f1_list = []\n",
    "\n",
    "for images, masks, mask_overlays, file_names in tqdm(test_dataloader):\n",
    "    batch_loss = 0.0 \n",
    "    batch_dice = 0.0  \n",
    "    batch_size = images.shape[0]  \n",
    "    for i in range(batch_size):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image = images[i].cpu().numpy()\n",
    "            mask = masks[i].cpu().numpy()\n",
    "            mask_overlay = mask_overlays[i]\n",
    "            file_name = file_names[i]\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "            _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            positive_point = extract_random_points(mask, 1)\n",
    "            negative_point = negative_random_point(mask, 1)\n",
    "    \n",
    "            negative_input_label = np.zeros((len(negative_point),), dtype=np.uint8)\n",
    "            input_label = np.ones((len(positive_point),), dtype=np.uint8)\n",
    "            _input_point = np.concatenate((positive_point, negative_point), axis=0)\n",
    "            _input_label = np.concatenate((input_label, negative_input_label), axis=0)\n",
    "            \n",
    "            predictor.set_image(image)\n",
    "            predict_masks, predict_scores, predict_logits = predictor.predict(\n",
    "            point_coords=_input_point,\n",
    "            point_labels=_input_label,\n",
    "            multimask_output=False)\n",
    "    \n",
    "            f1 = calculate_f1_score(mask, predict_masks[0])\n",
    "            show_masks_together(image, predict_masks, mask_overlay, f1, point_coords=_input_point, input_labels=_input_label, borders=True, save_path = f'{save_dir}/{file_name}')\n",
    "            f1_list.append((file_name, f1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
